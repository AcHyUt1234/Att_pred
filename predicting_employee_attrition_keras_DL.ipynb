{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "### What is Employee Attrition\n",
        "\n",
        "Employee attrition, especially those of key and star employees is a major concern for an HR organization. When employees leave, it has many side effects. There is loss of organizational and product-specific expertise, loss of productivity due to new hires taking time to onboard. Sometimes employees have great relationships with customers, and that is hard to rebuild. There are also hiring costs and training costs associated. Employees leave due to various reasons.\n",
        "\n",
        "They include compensation, work satisfaction, performance, and issues with their supervisors. The online world had made it easy for outside recruiters to approach employees with better job offers, which can make a content employee leave.\n",
        "\n",
        "### How can AI help in this employee attrition?\n",
        "\n",
        "First, we need to collect 360-degree data about the employee's past and present. This include, but not limited to the tenure in the company, performance ratings, compensation and promotions. Relationships the employee has with their supervisor and peers also play a key part. 360 reviews will help understand this. Once the data is collected and associated with both past and present employees, it provides input to build an ML model to predict attrition. Then, HR can take preventive action that is needed."
      ],
      "metadata": {
        "id": "WAmPT4yAbB6j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Using Deep Learning\n",
        "\n",
        "Let's quickly review the concept of classification in machine learning and its implementation in deep learning. Classification is a machine learning problem of identifying a set of categories to which a new observation belongs based on a training dataset that contains observations for which the category is already known. Classification is the most common type of machine learning problem.\n",
        "\n",
        "Examples include binary classification, like if a customer would buy a product or not, or multiclass classification, like determining the type of customer based on customer demographics. There are also a number of libraries that provide implementation of these algorithms. In Python, the most popular one is scikit-learn.\n",
        "\n",
        "In recent years, deep learning has revolutionized classification with its ability to handle complex relationships and generate highly accurate models. If you're not familiar with deep learning, I recommend watching other courses on this website that explains the basics of deep learning.\n",
        "\n",
        "We will use Keras library with TensorFlow backend for building the classification model."
      ],
      "metadata": {
        "id": "TVkL9E2_bB6q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# About The Dataset\n",
        "\n",
        "The dataset contains feature attributes that could possibly impact an employee's decision to leave the organization.\n",
        "\n",
        "The first column is employee ID.\n",
        "\n",
        "The second column is the total months of experience that the employee has overall.\n",
        "\n",
        "Total orgs worked is the total number of organizations the employee has worked so far.\n",
        "\n",
        "Months in org is the total number of months the employee has worked in this organization.\n",
        "\n",
        "Last pay increment band is a scale of one to five with one being the highest. The higher the band, the higher the pay raise for the employee in the last increment cycle.\n",
        "\n",
        "Next comes average feedback based on the 360 degree feedback the employee got in performance reviews. Again, it's a scale of one to five, with one being the highest rating.\n",
        "\n",
        "Last promotion years represent the total number of years since the last promotion for the employee.\n",
        "\n",
        "Finally, we have the target variable attrition, which indicates if the employee left the organization or not. This is only a representational data set. For your organization, you should do enough research to include all kinds of data that may possibly influence an employee's decision."
      ],
      "metadata": {
        "id": "nl_8AKVkbB6r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing Dataset"
      ],
      "metadata": {
        "id": "dhCISXbcbB6s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first load the data using pandas into a data frame, then we review the data loaded, its structure and its contents. We can see that the data has been loaded correctly. In classification, it's always a good idea to understand the relationship between the feature and the target variables, especially which feature variables have the most impact on the target variable. We do so using correlation analysis. Here, we do a correlation analysis on the target variable, attrition.\n",
        "\n",
        "We see that the LastPromotionYears has a significant impact on attrition, meaning that employees leave when they don't see enough career growth.\n",
        "\n",
        "Next, we prepare the data for machine learning. We first convert the dataset into a NumPy array of type float. This is the preferred input format for Keras.\n",
        "\n",
        "Next, we split the feature and the target variables into X and Y. We leave out the EmployeeID. We could additionally do center and scaling too, if the accuracy is too low. For the target variable, we will use One-Hot Encoding using the Keras to_categorical function. Since the attrition is Boolean, it has two unique values.\n",
        "\n",
        "Finally, we print the shapes on X and Y. Let's run this code and review the results. We see that there are a thousand samples. X has six columns for the six attributes. Y has two columns since it has One-Hot Encoding for two unique values. In the next video, we will build a model for attrition."
      ],
      "metadata": {
        "id": "2z2-DHT_bB6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the dataset and analyze\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "attrition_data = pd.read_csv(\"employee_attrition.csv\")\n",
        "\n",
        "print(\"Data Loaded:\\n------------------------\\n\",attrition_data.dtypes)\n",
        "attrition_data.head()\n",
        "attrition_data.shape"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2022-06-14T10:55:53.891579Z",
          "iopub.execute_input": "2022-06-14T10:55:53.892503Z",
          "iopub.status.idle": "2022-06-14T10:56:00.254243Z",
          "shell.execute_reply.started": "2022-06-14T10:55:53.892411Z",
          "shell.execute_reply": "2022-06-14T10:56:00.253513Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QJg-crQbB6u",
        "outputId": "8fe03b11-52fd-4a9d-a448-f87f9fdd3587"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Loaded:\n",
            "------------------------\n",
            " EmployeeID              int64\n",
            "TotalMonthsOfExp        int64\n",
            "TotalOrgsWorked         int64\n",
            "MonthsInOrg             int64\n",
            "LastPayIncrementBand    int64\n",
            "AverageFeedback         int64\n",
            "LastPromotionYears      int64\n",
            "Attrition               int64\n",
            "dtype: object\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attrition_data.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "pa7u-P0Xh8Si",
        "outputId": "8edcf581-23e3-4ca7-afe2-c69cac485f6f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        EmployeeID  TotalMonthsOfExp  TotalOrgsWorked  MonthsInOrg  \\\n",
              "count  1000.000000       1000.000000      1000.000000  1000.000000   \n",
              "mean    500.500000         61.002000         3.056000    31.000000   \n",
              "std     288.819436         34.818132         1.398148    26.783341   \n",
              "min       1.000000          1.000000         1.000000     0.000000   \n",
              "25%     250.750000         31.000000         2.000000     9.000000   \n",
              "50%     500.500000         61.000000         3.000000    23.000000   \n",
              "75%     750.250000         91.250000         4.000000    48.000000   \n",
              "max    1000.000000        120.000000         5.000000   116.000000   \n",
              "\n",
              "       LastPayIncrementBand  AverageFeedback  LastPromotionYears    Attrition  \n",
              "count           1000.000000      1000.000000          1000.00000  1000.000000  \n",
              "mean               3.063000         2.539000             2.45400     0.230000  \n",
              "std                1.413162         1.143585             1.10413     0.421043  \n",
              "min                1.000000         1.000000             1.00000     0.000000  \n",
              "25%                2.000000         1.000000             1.00000     0.000000  \n",
              "50%                3.000000         3.000000             2.00000     0.000000  \n",
              "75%                4.000000         4.000000             3.00000     0.000000  \n",
              "max                5.000000         4.000000             4.00000     1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e4dee20e-3f9b-4f35-ab23-ac2dd61b11ee\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EmployeeID</th>\n",
              "      <th>TotalMonthsOfExp</th>\n",
              "      <th>TotalOrgsWorked</th>\n",
              "      <th>MonthsInOrg</th>\n",
              "      <th>LastPayIncrementBand</th>\n",
              "      <th>AverageFeedback</th>\n",
              "      <th>LastPromotionYears</th>\n",
              "      <th>Attrition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.00000</td>\n",
              "      <td>1000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>500.500000</td>\n",
              "      <td>61.002000</td>\n",
              "      <td>3.056000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>3.063000</td>\n",
              "      <td>2.539000</td>\n",
              "      <td>2.45400</td>\n",
              "      <td>0.230000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>288.819436</td>\n",
              "      <td>34.818132</td>\n",
              "      <td>1.398148</td>\n",
              "      <td>26.783341</td>\n",
              "      <td>1.413162</td>\n",
              "      <td>1.143585</td>\n",
              "      <td>1.10413</td>\n",
              "      <td>0.421043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>250.750000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>500.500000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.00000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>750.250000</td>\n",
              "      <td>91.250000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.00000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1000.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>116.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4dee20e-3f9b-4f35-ab23-ac2dd61b11ee')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e4dee20e-3f9b-4f35-ab23-ac2dd61b11ee button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e4dee20e-3f9b-4f35-ab23-ac2dd61b11ee');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-96fd5d9f-937b-41fc-9818-fcb1eb97af28\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-96fd5d9f-937b-41fc-9818-fcb1eb97af28')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-96fd5d9f-937b-41fc-9818-fcb1eb97af28 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Correlation Analysis of target attribute\n",
        "\n",
        "attrition_data.corr()['Attrition']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-14T10:56:05.113353Z",
          "iopub.execute_input": "2022-06-14T10:56:05.114247Z",
          "iopub.status.idle": "2022-06-14T10:56:05.129256Z",
          "shell.execute_reply.started": "2022-06-14T10:56:05.114207Z",
          "shell.execute_reply": "2022-06-14T10:56:05.128589Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-oNOTOhbB6y",
        "outputId": "5caf2d10-97bd-4844-b84b-29a50b034cf2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EmployeeID             -0.036630\n",
              "TotalMonthsOfExp        0.019702\n",
              "TotalOrgsWorked         0.008706\n",
              "MonthsInOrg             0.012605\n",
              "LastPayIncrementBand    0.108528\n",
              "AverageFeedback        -0.008253\n",
              "LastPromotionYears      0.765641\n",
              "Attrition               1.000000\n",
              "Name: Attrition, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert to Dataframe to numpy array\n",
        "np_attrition = attrition_data.to_numpy().astype(float)\n",
        "\n",
        "#Create X_train with the first 7 attributes\n",
        "X_train = np_attrition[:,1:7]\n",
        "#Create Y_train with attrition attribute\n",
        "Y_train=np_attrition[:,7]\n",
        "\n",
        "#Convert Y_train to one-hot-encoding\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train,2)\n",
        "\n",
        "print(\"X-Train Shape : \", X_train.shape)\n",
        "print(\"Y-Train Shape : \", Y_train.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-14T10:56:06.273215Z",
          "iopub.execute_input": "2022-06-14T10:56:06.273604Z",
          "iopub.status.idle": "2022-06-14T10:56:07.461980Z",
          "shell.execute_reply.started": "2022-06-14T10:56:06.273574Z",
          "shell.execute_reply": "2022-06-14T10:56:07.460974Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTAGnj0jbB6z",
        "outputId": "aedb31ab-4e19-491f-b96d-a60553907fad"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X-Train Shape :  (1000, 6)\n",
            "Y-Train Shape :  (1000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Attrition Model With Keras\n",
        "\n",
        "We start off by setting up the hyper parameters for the model. We will use an epoch of 100 and a batch size of 100. We will set verbose to one so that we can see the training results. The number of unique output classes is two. We will create hidden layers for 128 units. We will also do a validation split of 0.2. This means 20% of the data will be used for validation while building the model. I highly recommend experimenting with the hyper parameters to understand how they impact model accuracy.\n",
        "\n",
        "Now, we can create a Keras model. Then we add a dense, hidden layer with ReLU as activation. We then add a second hidden layer. Finally, we add an output dense layer with softmax activation. We compiled the model with Adam optimizer and use categorical crossentropy as the last function. We also measure the accuracy of the model. Then we fit the model for this input data. This set of steps is a standard template for building basic deep learning models.We can see that the model ended up with an accuracy of 99%."
      ],
      "metadata": {
        "id": "VwNMFRwxbB60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "#Setup hyperparameters for deep learning\n",
        "EPOCHS=100\n",
        "BATCH_SIZE=100\n",
        "VERBOSE=1\n",
        "NB_CLASSES=2\n",
        "N_HIDDEN=128\n",
        "VALIDATION_SPLIT=0.2\n",
        "\n",
        "#Create a Keras model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "#Add first hidden Dense layer\n",
        "model.add(keras.layers.Dense(N_HIDDEN,\n",
        "                             input_shape=(6,),\n",
        "                              name='Dense-Layer-1',\n",
        "                              activation='relu'))\n",
        "\n",
        "#Add a second hidden dense layer\n",
        "model.add(keras.layers.Dense(N_HIDDEN,\n",
        "                              name='Dense-Layer-2',\n",
        "                              activation='relu'))\n",
        "\n",
        "#Add a final layer with softmax\n",
        "model.add(keras.layers.Dense(NB_CLASSES,\n",
        "                             name='Final',\n",
        "                             activation='softmax'))\n",
        "\n",
        "#Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#Fit parameters\n",
        "model.fit(X_train,\n",
        "          Y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=VERBOSE,\n",
        "          validation_split=VALIDATION_SPLIT)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-14T10:56:10.282391Z",
          "iopub.execute_input": "2022-06-14T10:56:10.282778Z",
          "iopub.status.idle": "2022-06-14T10:56:17.760575Z",
          "shell.execute_reply.started": "2022-06-14T10:56:10.282747Z",
          "shell.execute_reply": "2022-06-14T10:56:17.759535Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYU4xzwcbB61",
        "outputId": "b2be44d9-792a-4929-ce44-dfa6a424a05a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 35ms/step - loss: 1.0907 - accuracy: 0.6538 - val_loss: 0.7323 - val_accuracy: 0.6000\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6519 - accuracy: 0.7275 - val_loss: 0.5775 - val_accuracy: 0.7650\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5594 - accuracy: 0.7638 - val_loss: 0.5637 - val_accuracy: 0.7850\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5279 - accuracy: 0.7688 - val_loss: 0.5161 - val_accuracy: 0.7800\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5039 - accuracy: 0.7800 - val_loss: 0.4816 - val_accuracy: 0.7850\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.4699 - accuracy: 0.7950 - val_loss: 0.4890 - val_accuracy: 0.7800\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4442 - accuracy: 0.8163 - val_loss: 0.4432 - val_accuracy: 0.8000\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4074 - accuracy: 0.8175 - val_loss: 0.3964 - val_accuracy: 0.8450\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3974 - accuracy: 0.8263 - val_loss: 0.3848 - val_accuracy: 0.8600\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3690 - accuracy: 0.8462 - val_loss: 0.4344 - val_accuracy: 0.8150\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3839 - accuracy: 0.8175 - val_loss: 0.3635 - val_accuracy: 0.8350\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3436 - accuracy: 0.8475 - val_loss: 0.3345 - val_accuracy: 0.8550\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3213 - accuracy: 0.8625 - val_loss: 0.3315 - val_accuracy: 0.8750\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3238 - accuracy: 0.8662 - val_loss: 0.3735 - val_accuracy: 0.8350\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3096 - accuracy: 0.8562 - val_loss: 0.3050 - val_accuracy: 0.8800\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3004 - accuracy: 0.8637 - val_loss: 0.2940 - val_accuracy: 0.8750\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3081 - accuracy: 0.8550 - val_loss: 0.2884 - val_accuracy: 0.8900\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2657 - accuracy: 0.8913 - val_loss: 0.2935 - val_accuracy: 0.8700\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2843 - accuracy: 0.8800 - val_loss: 0.3507 - val_accuracy: 0.8500\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2883 - accuracy: 0.8737 - val_loss: 0.4145 - val_accuracy: 0.8250\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2740 - accuracy: 0.8737 - val_loss: 0.2860 - val_accuracy: 0.8750\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2595 - accuracy: 0.8913 - val_loss: 0.2807 - val_accuracy: 0.8900\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2523 - accuracy: 0.8988 - val_loss: 0.2592 - val_accuracy: 0.9050\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2700 - accuracy: 0.8875 - val_loss: 0.3315 - val_accuracy: 0.8500\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2460 - accuracy: 0.8950 - val_loss: 0.2550 - val_accuracy: 0.8800\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2372 - accuracy: 0.9013 - val_loss: 0.2568 - val_accuracy: 0.9100\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2292 - accuracy: 0.8975 - val_loss: 0.2972 - val_accuracy: 0.8600\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2335 - accuracy: 0.9000 - val_loss: 0.2765 - val_accuracy: 0.9050\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2239 - accuracy: 0.9125 - val_loss: 0.3219 - val_accuracy: 0.8550\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3297 - accuracy: 0.8475 - val_loss: 0.2380 - val_accuracy: 0.9100\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2767 - accuracy: 0.8700 - val_loss: 0.2709 - val_accuracy: 0.8950\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2316 - accuracy: 0.9062 - val_loss: 0.2552 - val_accuracy: 0.8700\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2626 - accuracy: 0.8850 - val_loss: 0.3105 - val_accuracy: 0.8400\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2347 - accuracy: 0.9038 - val_loss: 0.2225 - val_accuracy: 0.9000\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2141 - accuracy: 0.9087 - val_loss: 0.2390 - val_accuracy: 0.9100\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2146 - accuracy: 0.9150 - val_loss: 0.2160 - val_accuracy: 0.9200\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1951 - accuracy: 0.9275 - val_loss: 0.2205 - val_accuracy: 0.9000\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1886 - accuracy: 0.9262 - val_loss: 0.2076 - val_accuracy: 0.9300\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1805 - accuracy: 0.9287 - val_loss: 0.2085 - val_accuracy: 0.9100\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1777 - accuracy: 0.9362 - val_loss: 0.2295 - val_accuracy: 0.8850\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1741 - accuracy: 0.9275 - val_loss: 0.2158 - val_accuracy: 0.8950\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1762 - accuracy: 0.9362 - val_loss: 0.1983 - val_accuracy: 0.9350\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1701 - accuracy: 0.9362 - val_loss: 0.2135 - val_accuracy: 0.9150\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1842 - accuracy: 0.9162 - val_loss: 0.1946 - val_accuracy: 0.9450\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1811 - accuracy: 0.9312 - val_loss: 0.1930 - val_accuracy: 0.9250\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1624 - accuracy: 0.9488 - val_loss: 0.1922 - val_accuracy: 0.9300\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1629 - accuracy: 0.9450 - val_loss: 0.2083 - val_accuracy: 0.9000\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1582 - accuracy: 0.9463 - val_loss: 0.1824 - val_accuracy: 0.9300\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1585 - accuracy: 0.9475 - val_loss: 0.1857 - val_accuracy: 0.9450\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1741 - accuracy: 0.9312 - val_loss: 0.2787 - val_accuracy: 0.8700\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1632 - accuracy: 0.9312 - val_loss: 0.1836 - val_accuracy: 0.9450\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1463 - accuracy: 0.9475 - val_loss: 0.1761 - val_accuracy: 0.9350\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1489 - accuracy: 0.9538 - val_loss: 0.1760 - val_accuracy: 0.9450\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1465 - accuracy: 0.9425 - val_loss: 0.2056 - val_accuracy: 0.9050\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1825 - accuracy: 0.9225 - val_loss: 0.1710 - val_accuracy: 0.9400\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1732 - accuracy: 0.9275 - val_loss: 0.3573 - val_accuracy: 0.8550\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2317 - accuracy: 0.9050 - val_loss: 0.1874 - val_accuracy: 0.9100\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2010 - accuracy: 0.9112 - val_loss: 0.2360 - val_accuracy: 0.8900\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1899 - accuracy: 0.9062 - val_loss: 0.1690 - val_accuracy: 0.9400\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1385 - accuracy: 0.9513 - val_loss: 0.1850 - val_accuracy: 0.9200\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1293 - accuracy: 0.9638 - val_loss: 0.1527 - val_accuracy: 0.9400\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1258 - accuracy: 0.9638 - val_loss: 0.1512 - val_accuracy: 0.9500\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1450 - accuracy: 0.9450 - val_loss: 0.1730 - val_accuracy: 0.9300\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1258 - accuracy: 0.9588 - val_loss: 0.1828 - val_accuracy: 0.9200\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1273 - accuracy: 0.9600 - val_loss: 0.1968 - val_accuracy: 0.9200\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1513 - accuracy: 0.9350 - val_loss: 0.2384 - val_accuracy: 0.8750\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1283 - accuracy: 0.9475 - val_loss: 0.2168 - val_accuracy: 0.8800\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1345 - accuracy: 0.9563 - val_loss: 0.1503 - val_accuracy: 0.9450\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1230 - accuracy: 0.9550 - val_loss: 0.1550 - val_accuracy: 0.9450\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1133 - accuracy: 0.9663 - val_loss: 0.1430 - val_accuracy: 0.9450\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1121 - accuracy: 0.9700 - val_loss: 0.2067 - val_accuracy: 0.8800\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1289 - accuracy: 0.9588 - val_loss: 0.1452 - val_accuracy: 0.9500\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1302 - accuracy: 0.9525 - val_loss: 0.1599 - val_accuracy: 0.9300\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1309 - accuracy: 0.9550 - val_loss: 0.2319 - val_accuracy: 0.8700\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1549 - accuracy: 0.9388 - val_loss: 0.1323 - val_accuracy: 0.9600\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1228 - accuracy: 0.9538 - val_loss: 0.1505 - val_accuracy: 0.9250\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1136 - accuracy: 0.9563 - val_loss: 0.1328 - val_accuracy: 0.9600\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1081 - accuracy: 0.9663 - val_loss: 0.1599 - val_accuracy: 0.9250\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.1036 - accuracy: 0.9700 - val_loss: 0.1312 - val_accuracy: 0.9500\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1011 - accuracy: 0.9712 - val_loss: 0.1290 - val_accuracy: 0.9500\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0935 - accuracy: 0.9762 - val_loss: 0.1372 - val_accuracy: 0.9500\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1000 - accuracy: 0.9675 - val_loss: 0.1209 - val_accuracy: 0.9500\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0896 - accuracy: 0.9825 - val_loss: 0.1407 - val_accuracy: 0.9350\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0943 - accuracy: 0.9750 - val_loss: 0.1249 - val_accuracy: 0.9500\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0985 - accuracy: 0.9725 - val_loss: 0.1979 - val_accuracy: 0.8950\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1049 - accuracy: 0.9688 - val_loss: 0.1396 - val_accuracy: 0.9400\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0898 - accuracy: 0.9775 - val_loss: 0.1138 - val_accuracy: 0.9600\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0839 - accuracy: 0.9825 - val_loss: 0.1165 - val_accuracy: 0.9500\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0894 - accuracy: 0.9750 - val_loss: 0.1543 - val_accuracy: 0.9200\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0812 - accuracy: 0.9837 - val_loss: 0.1307 - val_accuracy: 0.9450\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0864 - accuracy: 0.9775 - val_loss: 0.1211 - val_accuracy: 0.9500\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0858 - accuracy: 0.9750 - val_loss: 0.1281 - val_accuracy: 0.9450\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0896 - accuracy: 0.9725 - val_loss: 0.1410 - val_accuracy: 0.9300\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0851 - accuracy: 0.9775 - val_loss: 0.1076 - val_accuracy: 0.9600\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0883 - accuracy: 0.9688 - val_loss: 0.1074 - val_accuracy: 0.9500\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0925 - accuracy: 0.9775 - val_loss: 0.1342 - val_accuracy: 0.9400\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0798 - accuracy: 0.9775 - val_loss: 0.1088 - val_accuracy: 0.9700\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0754 - accuracy: 0.9887 - val_loss: 0.1180 - val_accuracy: 0.9450\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0878 - accuracy: 0.9700 - val_loss: 0.1017 - val_accuracy: 0.9550\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0750 - accuracy: 0.9825 - val_loss: 0.1096 - val_accuracy: 0.9700\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79ccd85c2b00>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import save_model\n",
        "\n",
        "# Save the model to an HDF5 file\n",
        "model.save('your_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDwQQA8Pa79u",
        "outputId": "4a573ce8-e017-4a07-e3ce-2fa75464b4a5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting Attrition With Keras\n",
        "\n",
        "In order to predict attrition, we need to get the same set of six feature variables about the new employee for whom we need to predict attrition. Prediction then is an easy call to the model.predict_classes method that will output a zero or one based on the features.\n",
        "\n",
        "We can see that the algorithm predicts that the employee will leave. We can also do bulk predictions for multiple employees. We need to create an array of arrays with the inner array representing an employee. The method call is the same.\n",
        "\n",
        "I would strongly recommend using additional data points as well as experimenting with hyperparameters and layers for your own model."
      ],
      "metadata": {
        "id": "fi-GLvTPbB62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the model using pickle\n",
        "with open('your_model1.pkl', 'wb') as file:\n",
        "    pickle.dump(model, file)"
      ],
      "metadata": {
        "id": "2mAhvNvvbzWk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TotalMonthsOfExp=40\n",
        "TotalOrgsWorked=4\n",
        "MonthsInOrg=20\n",
        "LastPayIncrementBand=5\n",
        "AverageFeedback=4\n",
        "LastPromotionYears=4\n",
        "\n",
        "print(\"Will employee leave ?\")\n",
        "\n",
        "prediction= np.argmax(model.predict([[TotalMonthsOfExp,\n",
        "                                  TotalOrgsWorked,\n",
        "                                  MonthsInOrg,\n",
        "                                  LastPayIncrementBand,\n",
        "                                  AverageFeedback,\n",
        "                                  LastPromotionYears]]), axis=1)\n",
        "print(prediction)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-14T10:59:31.624377Z",
          "iopub.execute_input": "2022-06-14T10:59:31.624771Z",
          "iopub.status.idle": "2022-06-14T10:59:31.709206Z",
          "shell.execute_reply.started": "2022-06-14T10:59:31.624742Z",
          "shell.execute_reply": "2022-06-14T10:59:31.708048Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VD9iC4TbB63",
        "outputId": "0fe889bf-2049-4fa5-a31e-0e7972a76b87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Will employee leave ?\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## PREDICTION: ATTRITION PERCENTAGE\n",
        "\n",
        "TotalMonthsOfExp=40\n",
        "TotalOrgsWorked=4\n",
        "MonthsInOrg=20\n",
        "LastPayIncrementBand=5\n",
        "AverageFeedback=4\n",
        "LastPromotionYears=4\n",
        "\n",
        "print(\"Will employee leave ?\")\n",
        "\n",
        "prediction= model.predict([[TotalMonthsOfExp,\n",
        "                                  TotalOrgsWorked,\n",
        "                                  MonthsInOrg,\n",
        "                                  LastPayIncrementBand,\n",
        "                                  AverageFeedback,\n",
        "                                  LastPromotionYears]])\n",
        "print(round(prediction[0][1]*100,2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DT9wHH_Mjn_m",
        "outputId": "94f722cc-a830-472d-d485-a315c7d9e9f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Will employee leave ?\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "91.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TESTING\n",
        "\n",
        "TotalMonthsOfExp=80\n",
        "TotalOrgsWorked=2\n",
        "MonthsInOrg=40\n",
        "LastPayIncrementBand=5\n",
        "AverageFeedback=4\n",
        "LastPromotionYears=4\n",
        "\n",
        "print(\"Will employee leave ?\")\n",
        "\n",
        "prediction= model.predict([[TotalMonthsOfExp,\n",
        "                                  TotalOrgsWorked,\n",
        "                                  MonthsInOrg,\n",
        "                                  LastPayIncrementBand,\n",
        "                                  AverageFeedback,\n",
        "                                  LastPromotionYears]])\n",
        "print(round(prediction[0][1]*100,2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eyp5oW8pFe6",
        "outputId": "43c5eb71-3b53-4d06-81bf-035aab87911c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Will employee leave ?\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "84.26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Bulk predictions\n",
        "\n",
        "bulk_pred=np.argmax(model.predict(\n",
        "    [[111,5,85,3,2,2],\n",
        "    [31,2,15,4,1,4],\n",
        "    [61,4,24,1,4,3],\n",
        "    [77,4,35,3,1,1],\n",
        "    [81,5,7,1,2,3],\n",
        "    [113,4,112,5,4,1],\n",
        "    [101,2,48,5,1,4],\n",
        "    [45,4,22,5,3,1],\n",
        "    [25,2,2,2,3,2],\n",
        "    [97,3,15,3,2,4]]), axis=1)\n",
        "\n",
        "bulk_pred"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-14T11:00:24.804840Z",
          "iopub.execute_input": "2022-06-14T11:00:24.805256Z",
          "iopub.status.idle": "2022-06-14T11:00:24.929335Z",
          "shell.execute_reply.started": "2022-06-14T11:00:24.805223Z",
          "shell.execute_reply": "2022-06-14T11:00:24.928224Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cBu95FQbB64",
        "outputId": "07ba95e5-707d-43fe-a7cc-324177fb93e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 37ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 0, 0, 1, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}